{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "sys.path.append(\"game/\")\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import wrapped_flappy_bird as game\n",
    "\n",
    "from DQN import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert images to 80*80 gray images\n",
    "def preprocess(observation):\n",
    "    img = cv2.resize(observation, (80, 80))\n",
    "    observation = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, observation = cv2.threshold(observation,1,255,cv2.THRESH_BINARY)\n",
    "    return np.reshape(observation,(80,80,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG(object):\n",
    "    lr=0.001\n",
    "    actions=2\n",
    "    is_traing=True\n",
    "    load_weight=False\n",
    "    gamma=0.99\n",
    "    batch_size=32\n",
    "    mem_size=5000\n",
    "    epsilon=0.9\n",
    "    initial_epsilon=1.\n",
    "    final_epsilon=0.1\n",
    "    observation=100\n",
    "    exploration=50000\n",
    "    max_episode=100000\n",
    "    save_checkpoint_freq = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_time_step = 0.\n",
    "flappyBird = game.GameState()\n",
    "cfg = CFG()\n",
    "dqn = DQN(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    dqn.model = dqn.model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "action=[1,0]\n",
    "o, r, terminal = flappyBird.frame_step(action)\n",
    "best_time_step = 0.\n",
    "o = preprocess(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(cfg.observation):\n",
    "    action = dqn.get_action_randomly()\n",
    "    o, r, terminal = flappyBird.frame_step(action)\n",
    "    o = preprocess(o)\n",
    "    dqn.storeTransition(o, action, r, terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in xrange(cfg.max_episode):\n",
    "    dqn.time_step = 0\n",
    "    total_reward = 0.\n",
    "    while True:\n",
    "        optimizer.zero_grad()\n",
    "        action = dqn.get_action()\n",
    "        o_next, r, terminal = flappyBird.frame_step(action)\n",
    "        total_reward += cfg.gamma**model.time_step * r\n",
    "        o_next = preprocess(o_next)\n",
    "        dqn.store_transition(o_next, action, r, terminal)\n",
    "        dqn.increase_time_step()\n",
    "        \n",
    "        dqn.trainByBatch()\n",
    "        \n",
    "        if terminal:\n",
    "            break\n",
    "    \n",
    "    print 'episode: {}, epsilon: {:.4f}, max time step: {}, total reward: {:.6f}'.format(\n",
    "            episode, dqn.epsilon, dqn.time_step, total_reward)\n",
    "    \n",
    "    if dqn.epsilon > cfg.final_e:\n",
    "        delta = (cfg.init_e - cfg.final_e)/cfg.exploration\n",
    "        dqn.epsilon -= delta\n",
    "    \n",
    "    if episode % 100 == 0:\n",
    "        ave_time = test_dqn(model, episode)\n",
    "    \n",
    "    if ave_time > best_time_step:\n",
    "        best_time_step = ave_time\n",
    "        save_checkpoint({\n",
    "                'episode': episode,\n",
    "                'epsilon': dqn.epsilon,\n",
    "                'state_dict': dqn.state_dict(),\n",
    "                'best_time_step': best_time_step,\n",
    "                 }, True, 'checkpoint-episode-%d.pth.tar' %episode)\n",
    "    elif episode % cfg.save_checkpoint_freq == 0:\n",
    "        save_checkpoint({\n",
    "                'episode:': episode,\n",
    "                'epsilon': dqn.epsilon,\n",
    "                'state_dict': dqn.state_dict(),\n",
    "                'time_step': ave_time,\n",
    "                 }, False, 'checkpoint-episode-%d.pth.tar' %episode)\n",
    "    else:\n",
    "        continue\n",
    "    print 'save checkpoint, episode={}, ave time step={:.2f}'.format(\n",
    "                episode, ave_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dqn(model, options, resume):\n",
    "    \"\"\"Train DQN\n",
    "       model -- DQN model\n",
    "       lr -- learning rate\n",
    "       max_episode -- maximum episode\n",
    "       resume -- resume previous model\n",
    "       model_name -- checkpoint file name\n",
    "    \"\"\"\n",
    "    best_time_step = 0.\n",
    "    if resume:\n",
    "        if options.weight is None:\n",
    "            print 'when resume, you should give weight file name.'\n",
    "            return\n",
    "        print 'load previous model weight: {}'.format(options.weight)\n",
    "        _, _, best_time_step = load_checkpoint(options.weight, model)\n",
    "\n",
    "    flappyBird = game.GameState()\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=options.lr)\n",
    "    ceriterion = nn.MSELoss()\n",
    "\n",
    "    action = [1, 0]\n",
    "    o, r, terminal = flappyBird.frame_step(action)\n",
    "    o = preprocess(o)\n",
    "    model.set_initial_state()\n",
    "\n",
    "    if options.cuda:\n",
    "        model = model.cuda()\n",
    "    # in the first `OBSERVE` time steos, we dont train the model\n",
    "    for i in xrange(options.observation):\n",
    "        action = model.get_action_randomly()\n",
    "        o, r, terminal = flappyBird.frame_step(action)\n",
    "        o = preprocess(o)\n",
    "        model.store_transition(o, action, r, terminal)\n",
    "    # start training\n",
    "    for episode in xrange(options.max_episode):\n",
    "        model.time_step = 0\n",
    "        model.set_train()\n",
    "        total_reward = 0.\n",
    "        # begin an episode!\n",
    "        while True:\n",
    "            optimizer.zero_grad()\n",
    "            action = model.get_action()\n",
    "            o_next, r, terminal = flappyBird.frame_step(action)\n",
    "            total_reward += options.gamma**model.time_step * r\n",
    "            o_next = preprocess(o_next)\n",
    "            model.store_transition(o_next, action, r, terminal)\n",
    "            model.increase_time_step()\n",
    "            # Step 1: obtain random minibatch from replay memory\n",
    "            minibatch = random.sample(model.replay_memory, options.batch_size)\n",
    "            state_batch = np.array([data[0] for data in minibatch])\n",
    "            action_batch = np.array([data[1] for data in minibatch])\n",
    "            reward_batch = np.array([data[2] for data in minibatch])\n",
    "            next_state_batch = np.array([data[3] for data in minibatch])\n",
    "            state_batch_var = Variable(torch.from_numpy(state_batch))\n",
    "            next_state_batch_var = Variable(torch.from_numpy(next_state_batch),\n",
    "                                           volatile=True)\n",
    "            if options.cuda:\n",
    "                state_batch_var = state_batch_var.cuda()\n",
    "                next_state_batch_var = next_state_batch_var.cuda()\n",
    "            # Step 2: calculate y\n",
    "            q_value_next = model.forward(next_state_batch_var)\n",
    "\n",
    "            q_value = model.forward(state_batch_var)\n",
    "\n",
    "            y = reward_batch.astype(np.float32)\n",
    "            max_q, _ = torch.max(q_value_next, dim=1)\n",
    "\n",
    "            for i in xrange(options.batch_size):\n",
    "                if not minibatch[i][4]:\n",
    "                    y[i] += options.gamma*max_q.data[i][0]\n",
    "\n",
    "            y = Variable(torch.from_numpy(y))\n",
    "            action_batch_var = Variable(torch.from_numpy(action_batch))\n",
    "            if options.cuda:\n",
    "                y = y.cuda()\n",
    "                action_batch_var = action_batch_var.cuda()\n",
    "            q_value = torch.sum(torch.mul(action_batch_var, q_value), dim=1)\n",
    "\n",
    "            loss = ceriterion(q_value, y)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            # when the bird dies, the episode ends\n",
    "            if terminal:\n",
    "                break\n",
    "\n",
    "        print 'episode: {}, epsilon: {:.4f}, max time step: {}, total reward: {:.6f}'.format(\n",
    "                episode, cfg.epsilon, cfg.time_step, total_reward)\n",
    "\n",
    "        if model.epsilon > options.final_e:\n",
    "            delta = (options.init_e - options.final_e)/options.exploration\n",
    "            model.epsilon -= delta\n",
    "\n",
    "        if episode % 100 == 0:\n",
    "            ave_time = test_dqn(model, episode)\n",
    "\n",
    "        if ave_time > best_time_step:\n",
    "            best_time_step = ave_time\n",
    "            save_checkpoint({\n",
    "                'episode': episode,\n",
    "                'epsilon': model.epsilon,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'best_time_step': best_time_step,\n",
    "                 }, True, 'checkpoint-episode-%d.pth.tar' %episode)\n",
    "        elif episode % cfg.save_checkpoint_freq == 0:\n",
    "            save_checkpoint({\n",
    "                'episode:': episode,\n",
    "                'epsilon': model.epsilon,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'time_step': ave_time,\n",
    "                 }, False, 'checkpoint-episode-%d.pth.tar' %episode)\n",
    "        else:\n",
    "            continue\n",
    "        print 'save checkpoint, episode={}, ave time step={:.2f}'.format(\n",
    "                 episode, ave_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net (\n",
      "  (conv1): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (fc1): Linear (9216 -> 256)\n",
      "  (fc2): Linear (256 -> 2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(dqn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flappyBird = game.GameState()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = [1, 0]\n",
    "o, r, terminal = flappyBird.frame_step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
